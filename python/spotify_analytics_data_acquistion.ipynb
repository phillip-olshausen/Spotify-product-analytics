{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39eb7d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /Users/Phillip/spotify_product_analytics_sql\n",
      "Requirement already satisfied: pip in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (25.1.1)\n",
      "Collecting pip\n",
      "  Downloading pip-26.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-26.0.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.1.1\n",
      "    Uninstalling pip-25.1.1:\n",
      "      Successfully uninstalled pip-25.1.1\n",
      "Successfully installed pip-26.0.1\n",
      "Requirement already satisfied: pandas in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: pyarrow in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (23.0.0)\n",
      "Requirement already satisfied: datasets in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (4.5.0)\n",
      "Requirement already satisfied: tqdm in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: filelock in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from datasets) (1.3.7)\n",
      "Requirement already satisfied: packaging in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\n",
      "Requirement already satisfied: anyio in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpx<1.0.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpx<1.0.0->datasets) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (0.21.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (8.3.1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, subprocess, textwrap\n",
    "\n",
    "PROJECT_DIR = os.path.expanduser(\"~/spotify_product_analytics_sql\")\n",
    "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
    "os.chdir(PROJECT_DIR)\n",
    "print(\"Working directory:\", os.getcwd())\n",
    "\n",
    "# Install requirements (safe to re-run)\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"pip\"])\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pandas\", \"pyarrow\", \"datasets\", \"tqdm\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "665e8944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available splits: ['train', 'valid', 'test']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Export train: 100%|██████████| 27/27 [01:12<00:00,  2.69s/it]\n",
      "Export valid: 100%|██████████| 4/4 [00:08<00:00,  2.04s/it]\n",
      "Export test: 100%|██████████| 5/5 [00:10<00:00,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: ['events_test.csv', 'events_train.csv', 'events_valid.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "OUT_DIR = \"data\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "DATASET_ID = \"matthewfranglen/lastfm-1k\"\n",
    "\n",
    "ds = load_dataset(DATASET_ID)\n",
    "print(\"Available splits:\", list(ds.keys()))  # should be ['train','valid','test']\n",
    "\n",
    "def export_split(split_name: str, out_csv: str, chunksize: int = 500_000):\n",
    "    d = ds[split_name]\n",
    "    cols = list(d.column_names)\n",
    "\n",
    "    # write header\n",
    "    with open(out_csv, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\",\".join(cols) + \"\\n\")\n",
    "\n",
    "    total = len(d)\n",
    "    for start in tqdm(range(0, total, chunksize), desc=f\"Export {split_name}\"):\n",
    "        end = min(start + chunksize, total)\n",
    "        batch = d.select(range(start, end)).to_pandas()\n",
    "        batch.to_csv(out_csv, mode=\"a\", index=False, header=False)\n",
    "\n",
    "for split in ds.keys():\n",
    "    export_split(split, os.path.join(OUT_DIR, f\"events_{split}.csv\"))\n",
    "\n",
    "print(\"Wrote:\", sorted([f for f in os.listdir(OUT_DIR) if f.startswith(\"events_\")]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee31fd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read train: 35chunk [00:24,  1.47chunk/s]/Users/Phillip/.pyenv/versions/3.11.8/lib/python3.11/site-packages/tqdm/std.py:1181: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for obj in iterable:\n",
      "Read train: 45chunk [00:30,  1.47chunk/s]\n",
      "Read valid: 6chunk [00:03,  1.71chunk/s]\n",
      "Read test: 7chunk [00:04,  1.46chunk/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote data/plays.csv and data/users.csv\n",
      "Rows - plays: 16936134 users: 992\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "IN_DIR = \"data\"\n",
    "OUT_DIR = \"data\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# detect which exported files exist\n",
    "SPLIT_FILES = []\n",
    "for split in (\"train\", \"valid\", \"test\"):\n",
    "    path = os.path.join(IN_DIR, f\"events_{split}.csv\")\n",
    "    if os.path.exists(path):\n",
    "        SPLIT_FILES.append((split, path))\n",
    "\n",
    "if not SPLIT_FILES:\n",
    "    raise FileNotFoundError(\"No exported events CSVs found. Run Block 1 first.\")\n",
    "\n",
    "USER_COL_CANDIDATES = [\"user_id\", \"user\"]\n",
    "TS_COL_CANDIDATES = [\"timestamp\", \"played_at\", \"time\", \"datetime\", \"date_time\", \"utc_time\"]\n",
    "\n",
    "ARTIST_ID_CANDIDATES = [\"artist_id\", \"musicbrainz_artist_id\"]\n",
    "ARTIST_NAME_CANDIDATES = [\"artist_name\", \"artist\"]\n",
    "\n",
    "TRACK_ID_CANDIDATES = [\"track_id\", \"musicbrainz_track_id\"]\n",
    "TRACK_NAME_CANDIDATES = [\"track_name\", \"track\", \"title\"]\n",
    "\n",
    "PROFILE_COUNTRY_CANDIDATES = [\"country\"]\n",
    "PROFILE_SIGNUP_CANDIDATES = [\"signup\", \"signup_date\", \"registration_date\"]\n",
    "PROFILE_GENDER_CANDIDATES = [\"gender\"]\n",
    "PROFILE_AGE_CANDIDATES = [\"age\"]\n",
    "\n",
    "def pick_col(cols, candidates):\n",
    "    for c in candidates:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def load_in_chunks(path, chunksize=300_000):\n",
    "    return pd.read_csv(path, chunksize=chunksize)\n",
    "\n",
    "plays_frames = []\n",
    "users_frames = []\n",
    "\n",
    "for split_name, path in SPLIT_FILES:\n",
    "    for chunk in tqdm(load_in_chunks(path), desc=f\"Read {split_name}\", unit=\"chunk\"):\n",
    "        cols = list(chunk.columns)\n",
    "\n",
    "        ucol = pick_col(cols, USER_COL_CANDIDATES)\n",
    "        tcol = pick_col(cols, TS_COL_CANDIDATES)\n",
    "        if ucol is None or tcol is None:\n",
    "            raise ValueError(\n",
    "                f\"Could not find user/timestamp columns in {path}. \"\n",
    "                f\"First columns: {cols[:30]}\"\n",
    "            )\n",
    "\n",
    "        aid = pick_col(cols, ARTIST_ID_CANDIDATES)\n",
    "        anm = pick_col(cols, ARTIST_NAME_CANDIDATES)\n",
    "        tid = pick_col(cols, TRACK_ID_CANDIDATES)\n",
    "        tnm = pick_col(cols, TRACK_NAME_CANDIDATES)\n",
    "\n",
    "        country = pick_col(cols, PROFILE_COUNTRY_CANDIDATES)\n",
    "        signup  = pick_col(cols, PROFILE_SIGNUP_CANDIDATES)\n",
    "        gender  = pick_col(cols, PROFILE_GENDER_CANDIDATES)\n",
    "        age     = pick_col(cols, PROFILE_AGE_CANDIDATES)\n",
    "\n",
    "        plays = pd.DataFrame({\n",
    "            \"user_id\": chunk[ucol].astype(str),\n",
    "            \"played_at\": pd.to_datetime(chunk[tcol], errors=\"coerce\", utc=True),\n",
    "            \"artist_id\": chunk[aid].astype(str) if aid else None,\n",
    "            \"artist_name\": chunk[anm].astype(str) if anm else None,\n",
    "            \"track_id\": chunk[tid].astype(str) if tid else None,\n",
    "            \"track_name\": chunk[tnm].astype(str) if tnm else None,\n",
    "            \"split\": split_name,\n",
    "        }).dropna(subset=[\"user_id\", \"played_at\"])\n",
    "\n",
    "        plays_frames.append(plays)\n",
    "\n",
    "        # users (best-effort if metadata exists)\n",
    "        u = pd.DataFrame({\"user_id\": chunk[ucol].astype(str)})\n",
    "        u[\"country\"] = chunk[country].astype(str) if country else None\n",
    "        u[\"signup_date\"] = pd.to_datetime(chunk[signup], errors=\"coerce\").dt.date if signup else pd.NaT\n",
    "        u[\"gender\"] = chunk[gender].astype(str) if gender else None\n",
    "        u[\"age\"] = pd.to_numeric(chunk[age], errors=\"coerce\") if age else None\n",
    "        users_frames.append(u)\n",
    "\n",
    "plays_all = pd.concat(plays_frames, ignore_index=True).sort_values([\"user_id\", \"played_at\"])\n",
    "plays_all.to_csv(os.path.join(OUT_DIR, \"plays.csv\"), index=False)\n",
    "\n",
    "users_all = pd.concat(users_frames, ignore_index=True).drop_duplicates(subset=[\"user_id\"])\n",
    "users_all[\"plan\"] = \"free\"  # synthetic; just for segmentation structure\n",
    "users_all.to_csv(os.path.join(OUT_DIR, \"users.csv\"), index=False)\n",
    "\n",
    "print(\"Wrote data/plays.csv and data/users.csv\")\n",
    "print(\"Rows - plays:\", len(plays_all), \"users:\", len(users_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3696ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       user_id                  played_at  \\\n",
       " 0  user_000001  2006-08-13 13:59:20+00:00   \n",
       " 1  user_000001  2006-08-13 14:03:29+00:00   \n",
       " 2  user_000001  2006-08-13 14:10:43+00:00   \n",
       " 3  user_000001  2006-08-13 14:17:40+00:00   \n",
       " 4  user_000001  2006-08-13 14:19:06+00:00   \n",
       " \n",
       "                               artist_id        artist_name  \\\n",
       " 0  09a114d9-7723-4e14-b524-379697f6d2b5  Plaid & Bob Jaroc   \n",
       " 1  09a114d9-7723-4e14-b524-379697f6d2b5  Plaid & Bob Jaroc   \n",
       " 2  09a114d9-7723-4e14-b524-379697f6d2b5  Plaid & Bob Jaroc   \n",
       " 3  67fb65b5-6589-47f0-9371-8a40eb268dfb     Tommy Guerrero   \n",
       " 4  1cfbc7d1-299c-46e6-ba4c-1facb84ba435      Artful Dodger   \n",
       " \n",
       "                                track_id  \\\n",
       " 0  c4633ab1-e715-477f-8685-afa5f2058e42   \n",
       " 1  bc2765af-208c-44c5-b3b0-cf597a646660   \n",
       " 2  aa9c5a80-5cbe-42aa-a966-eb3cfa37d832   \n",
       " 3  d9b1c1da-7e47-4f97-a135-77260f2f559d   \n",
       " 4  120bb01c-03e4-465f-94a0-dce5e9fac711   \n",
       " \n",
       "                                  track_name  split  \n",
       " 0                 The Launching Of Big Face  train  \n",
       " 1                                   Zn Zero  train  \n",
       " 2  The Return Of Super Barrio - End Credits  train  \n",
       " 3                             Mission Flats  train  \n",
       " 4                        What You Gonna Do?  train  ,\n",
       "        user_id             country signup_date  gender   age  plan\n",
       " 0  user_000001               Japan  2006-08-13    male   NaN  free\n",
       " 1  user_000002                Peru  2006-02-24  female   NaN  free\n",
       " 2  user_000004                 NaN  2006-04-26  female   NaN  free\n",
       " 3  user_000005            Bulgaria  2006-06-29    male   NaN  free\n",
       " 4  user_000006  Russian Federation  2006-05-18     NaN  24.0  free)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "plays_preview = pd.read_csv(\"data/plays.csv\", nrows=5)\n",
    "users_preview = pd.read_csv(\"data/users.csv\", nrows=5)\n",
    "\n",
    "plays_preview, users_preview\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
